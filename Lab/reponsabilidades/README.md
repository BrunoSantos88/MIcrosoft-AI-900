# Entenda a IA responsável

Na Microsoft, o desenvolvimento de software de IA é guiado por um conjunto de seis princípios, projetados para garantir que os aplicativos de IA forneçam soluções surpreendentes para problemas difíceis sem quaisquer consequências negativas não intencionais.

# imparcialidade
Os sistemas de IA devem tratar todas as pessoas de maneira justa. Por exemplo, suponha que você crie um modelo de aprendizado de máquina para oferecer suporte a um aplicativo de aprovação de empréstimo para um banco. O modelo deve prever se o empréstimo deve ser aprovado ou negado sem viés. Esse viés pode ser baseado em gênero, etnia ou outros fatores que resultam em uma vantagem ou desvantagem injusta para grupos específicos de candidatos.

O Azure Machine Learning inclui a capacidade de interpretar modelos e quantificar até que ponto cada recurso dos dados influencia a previsão do modelo. Esse recurso ajuda cientistas de dados e desenvolvedores a identificar e mitigar o viés no modelo.

Outro exemplo é a implementação da Microsoft de IA responsável com o serviço Face , que retira os recursos de reconhecimento facial que podem ser usados ​​para tentar inferir estados emocionais e atributos de identidade. Esses recursos, se mal utilizados, podem sujeitar as pessoas a estereótipos, discriminação ou negação injusta de serviços.

# Confiabilidade e segurança
Os sistemas de IA devem funcionar de forma confiável e segura. Por exemplo, considere um sistema de software baseado em IA para um veículo autônomo; ou um modelo de aprendizado de máquina que diagnostica os sintomas do paciente e recomenda prescrições. A falta de confiabilidade nesses tipos de sistemas pode resultar em risco substancial para a vida humana.

O desenvolvimento de aplicativos de software baseados em IA deve ser submetido a testes rigorosos e processos de gerenciamento de implantação para garantir que funcionem conforme o esperado antes do lançamento.


# Privacidade e segurança
Os sistemas de IA devem ser seguros e respeitar a privacidade. Os modelos de aprendizado de máquina nos quais os sistemas de IA são baseados dependem de grandes volumes de dados, que podem conter detalhes pessoais que devem ser mantidos em sigilo. Mesmo após os modelos serem treinados e o sistema estar em produção, a privacidade e a segurança precisam ser consideradas. Como o sistema usa novos dados para fazer previsões ou agir, tanto os dados quanto as decisões tomadas com base nos dados podem estar sujeitos a questões de privacidade ou segurança.

# inclusão
Os sistemas de IA devem capacitar todos e envolver as pessoas. A IA deve trazer benefícios para todas as partes da sociedade, independentemente da capacidade física, gênero, orientação sexual, etnia ou outros fatores.

# Transparência
Os sistemas de IA devem ser compreensíveis. Os usuários devem estar totalmente cientes da finalidade do sistema, como ele funciona e quais limitações podem ser esperadas.

# Responsabilidade
As pessoas devem ser responsáveis pelos sistemas de IA. Designers e desenvolvedores de soluções baseadas em IA devem trabalhar dentro de uma estrutura de governança e princípios organizacionais que garantam que a solução atenda aos padrões éticos e legais claramente definidos.
